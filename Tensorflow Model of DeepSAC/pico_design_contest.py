# -*- coding: utf-8 -*-
"""PICO_Design_Contest

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kpudKlopE528_tWjGgrRDZ5b6xR8qU42
"""

##data mount
from google.colab import drive
drive.mount('drive')

import numpy as np

x = np.genfromtxt ('/content/drive/MyDrive/Physionet/Apnea_ecg/combined data/x_ap_avg.csv', delimiter=',', dtype = 'float32')
y = np.genfromtxt ('/content/drive/MyDrive/Physionet/Apnea_ecg/combined data/y_ap.csv', delimiter=',')

print(x.shape)
print(y.shape)

#Data Normalization and Pre-Processing
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
# define min max scaler
scaler = MinMaxScaler()
xs = scaler.fit_transform(x)
print(xs)

#train test split
from sklearn.model_selection import train_test_split
x_train, x_val, y_train, y_val = train_test_split(xs, y, test_size=0.30)
print(x_train.shape)
print(y_train.shape)
print(x_val.shape)
print(y_val.shape)

from sklearn.model_selection import StratifiedKFold
from keras.layers import LeakyReLU
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout
from keras.models import Model

# fix random seed for reproducibility
seed = 10
np.random.seed(seed)
# define 10-fold cross validation test harness
kfold = StratifiedKFold(n_splits=10  , shuffle=True, random_state=seed)
cvscores = []
for train, test in kfold.split(x_train, y_train):
  model = Sequential()
  model.add(Dense(8, input_dim = 2, activation = 'relu',use_bias= False))
  model.add(Dense(12, activation = 'relu',use_bias= False))
  model.add(Dense(6, activation = 'relu',use_bias= False))
  model.add(Dense(4, activation = 'relu',use_bias= False))
  model.add(Dense(1, activation = 'sigmoid',use_bias= False))
  
  #opt = SGD(lr=0.01, momentum=0.9)
  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
	# Fit the model
  model.fit(x_train[train], y_train[train], epochs=1000, batch_size=5, verbose=0)
	# evaluate the model
  scores = model.evaluate(x_train[test], y_train[test], verbose=0)
  print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
  cvscores.append(scores[1] * 100)
print("%.2f%% (+/- %.2f%%)" % (np.mean(cvscores), np.std(cvscores)))

model2.evaluate(x_val, y_val.round())

#confusion metrix generation
y_pred = model.predict(x_val)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, y_pred.round(), normalize= None)
print(cm) 

#precision
from sklearn.metrics import classification_report
print(classification_report(y_val, y_pred.round()))
#matrix = [TP, FP, 
#          FN, TN ]

"""## Binarization"""

bin0=model.layers[0].get_weights()
bin1=model.layers[1].get_weights()
bin2=model.layers[2].get_weights()
bin3=model.layers[3].get_weights()
bin4=model.layers[4].get_weights()

#evaluating model with shifter 
m = tf.keras.metrics.Mean()
b0 = m(tf.math.abs(bin0))*tf.keras.backend.sign(bin0)
b0= tf.reshape(b0, [2, 8]).numpy()
print(b0)

#evaluating model with shifter 
b1 = m(tf.math.abs(bin1))*tf.keras.backend.sign(bin1)
b1= tf.reshape(b1, [8, 12]).numpy()
print(b1)

#evaluating model with shifter 
b2 = m(tf.math.abs(bin2))*tf.keras.backend.sign(bin2)
b2= tf.reshape(b2, [12, 6]).numpy()
print(b2)

b3 = m(tf.math.abs(bin3))*tf.keras.backend.sign(bin3)
b3= tf.reshape(b3, [6, 4]).numpy()
print(b3)

b4 = m(tf.math.abs(bin4))*tf.keras.backend.sign(bin4)
b4= tf.reshape(b4, [4, 1]).numpy()
print(b4)

"""## Binary Conversion"""

b10= b0/0.31182504
print(b10)

b11= b1/0.47497058
print(b11)

b12= b2/0.6495637 
print(b12)

b13= b3/0.65885997
print(b13)

b14= b4/ 0.66857713
print(b14)

model.layers[0].set_weights([b10])
model.layers[1].set_weights([b11])
model_.layers[2].set_weights([b12])
model_bin.layers[3].set_weights([b13])
model_bin.layers[4].set_weights([b14])

model.evaluate(x_val, y_val)